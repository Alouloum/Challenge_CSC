model:
  lstm_hidden_dim: 32
  bidirectional: true
  embedding_dim: 200
  num_classes: 2
  max_tweets_per_group: 2000
  max_n_words: 20

training_args:
  output_dir: "./checkpoints/lstm/bilstm32"
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  eval_strategy: "epoch"
  logging_dir: "./logs/lstm/bilstm32"
  logging_steps: 10
  load_best_model_at_end: true
  save_strategy: "epoch"
  num_train_epochs: 20
  weight_decay: 0.01
  learning_rate: 0.0005
  save_total_limit: 2
  metric_for_best_model: "eval_accuracy"
  greater_is_better: true


